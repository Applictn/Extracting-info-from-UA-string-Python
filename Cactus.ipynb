{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ua_parser import user_agent_parser   # for user-agent string\n",
    "from urllib.parse import unquote          # for non-english words\n",
    "import urllib.parse\n",
    "from geolite2 import geolite2\n",
    "import sys\n",
    "import re\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "# pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding non-english words in native language\n",
    "# def encode(url):\n",
    "#     return urllib.parse.quote(url)\n",
    "\n",
    "# function to extract locations from ip address city, country, continent, subdivisions \n",
    "def location(data, loc):\n",
    "    geo = geolite2.reader()\n",
    "    data[loc]= ''\n",
    "\n",
    "    for i, ip in enumerate(data[\"geo_ip\"]):\n",
    "        x = geo.get(ip)\n",
    "        try:\n",
    "            data[loc].iloc[i] = x[loc]['names']['en']\n",
    "        except:\n",
    "            try:\n",
    "                data[loc].iloc[i] = x[loc][0]['names']['en']\n",
    "            except:\n",
    "                pass\n",
    "    geolite2.close()\n",
    "    \n",
    "\n",
    "# function to extract latitude, longitude, timezone etc...\n",
    "def lat_long(data):\n",
    "    data['latitude'] = ''\n",
    "    data['longitude'] = ''\n",
    "    data['time_zone'] = ''\n",
    "    data['metro_code'] = ''\n",
    "    \n",
    "    geo = geolite2.reader()\n",
    "    for i, ip in enumerate(data['geo_ip']):\n",
    "        x= geo.get(ip)\n",
    "        try:\n",
    "            data['latitude'].iloc[i] = x[\"location\"]['latitude']\n",
    "            data['longitude'].iloc[i] = x[\"location\"]['longitude']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data['time_zone'].iloc[i] = x[\"location\"]['time_zone']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            data['metro_code'].iloc[i] = x[\"location\"]['metro_code']\n",
    "        except:\n",
    "            pass\n",
    "    geolite2.close()\n",
    "    \n",
    "    \n",
    "# function to extract information from 'location query' column\n",
    "def extract(data, name):\n",
    "    data[name] = ''\n",
    "    for i, url in enumerate(data['location query']):\n",
    "        try:\n",
    "            data[name].iloc[i] = re.findall(f'{name}=(.*?)&', url)[0]\n",
    "        except:\n",
    "            try:\n",
    "                data[name].iloc[i] = re.findall(f'{name}=(.*)', url)[0]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    # reading the I/O file\n",
    "    data = pd.read_csv('sample_data.csv', encoding='utf-8')\n",
    "\n",
    "    # applying non-english decoder function\n",
    "#     data['location query']=data['location query'].apply(encode)\n",
    "\n",
    "\n",
    "    # Handling User-agent column and making new columns for browser, os, devices\n",
    "\n",
    "    ua = data['ua_string'].apply(lambda ua: user_agent_parser.Parse(ua))\n",
    "\n",
    "    data['browser'] = ua.apply(lambda x: x['user_agent']['family'])\n",
    "    data['os'] = ua.apply(lambda x: x['os']['family'])\n",
    "    data['operating_device'] = ua.apply(lambda x: x['device']['family'])\n",
    "    \n",
    "    # extract details from the url\n",
    "    extract(data,'creative')\n",
    "    extract(data,'keyword')\n",
    "    extract(data,'device')\n",
    "    extract(data,'matchtype')\n",
    "    extract(data,'n_media')\n",
    "    extract(data,'n_campaign_type')\n",
    "    extract(data,'gclid')\n",
    "    extract(data,'n_query')\n",
    "    extract(data,'n_keyword')\n",
    "    extract(data,'n_ad_group')\n",
    "\n",
    "    # applying function to extract geo info\n",
    "    lat_long(data)\n",
    "\n",
    "    # applying function to extract country details from geo_ip\n",
    "    location(data, 'city')\n",
    "    location(data, 'country')\n",
    "    location(data, 'continent')\n",
    "    location(data, 'subdivisions')\n",
    "    \n",
    "    data.replace('', np.nan, inplace=True)\n",
    "    \n",
    "    # Saving the updated file\n",
    "    data.to_csv('Data.csv', index=False)\n",
    "    \n",
    "    # table with top 10 keywords extracted from URL\n",
    "    url_feature = ['creative', 'keyword', 'device', 'matchtype', 'n_media', 'n_campaign_type', 'gclid', 'n_query', 'n_keyword', 'n_ad_group']\n",
    "\n",
    "    feature=[]\n",
    "    for features in url_feature:\n",
    "        feature.append(data[features].value_counts().index[:10])\n",
    "\n",
    "    data_value_count = pd.DataFrame(feature).T\n",
    "    data_value_count.columns= url_feature\n",
    "    \n",
    "    # Saving the file \n",
    "    data_value_count.to_csv('Data_count.csv', index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
